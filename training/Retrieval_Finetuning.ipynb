{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "II1hOipK5Tfg"
      },
      "source": [
        "# Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gp3jGQfOlTE4",
        "outputId": "46c5c6a7-29a8-4724-f3ae-e0d32438e91c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01rVamuvwXgP",
        "outputId": "92d8d4f5-e819-41f4-8e8e-fcda073f160d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.34.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.34.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.16.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.15.12)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.40)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.32.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install sentence_transformers\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uRhqGDcO8L4",
        "outputId": "8d9fc774-35e9-4a8d-a1c0-4b37a2db43f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['sent1', 'sent2', 'label']\n",
            "[['Cạnh đó, thanh niên quân đội và thanh niên tiền phon cũng phải thực hiện tốt công tác dân vận, tham gia tích cực vào các chương trình an sinh xã hội, xây dựng nông thôn mới, phòng, chống khắc phục thiên tai, dịch bệnh, xóa đói giảm nghèo.', 'Cạnh đó, thanh niên quân đội cũng phải thực hiện tốt công tác dân vận, tham gia tích cực vào các chương trình an sinh xã hội, xây dựng nông thôn mới, phòng, chống khắc phục thiên tai, dịch bệnh.', '1'], ['Cạnh đó, thanh niên quân đội và thanh niên tiền phon cũng phải thực hiện tốt công tác dân vận, tham gia tích cực vào các chương trình an sinh xã hội, xây dựng nông thôn mới, phòng, chống khắc phục thiên tai, dịch bệnh, xóa đói giảm nghèo.', 'Thay mặt 10 thanh niên tiêu biểu nhận bằng khen của Bộ trưởng Quốc phòng, thượng úy Lê Hảo (Trợ lý Thanh niên, Phòng Chính trị, Bộ Tư lệnh TP HCM) cho biết sau khi tốt nghiệp trường Sĩ quan Chính trị năm 2020, anh được phân công về Sư đoàn Gia Định. Đây là thời điểm TP HCM bước vào giai đoạn chống dịch Covid-19 cam go nhất.', '0'], ['Cạnh đó, thanh niên quân đội và thanh niên tiền phon cũng phải thực hiện tốt công tác dân vận, tham gia tích cực vào các chương trình an sinh xã hội, xây dựng nông thôn mới, phòng, chống khắc phục thiên tai, dịch bệnh, xóa đói giảm nghèo.', 'Chủ tịch nước đề nghị thanh niên quân đội không ngừng học tập, nâng cao trình độ, kiến thức tổng hợp và chuyên sâu, nâng cao khả năng tự học, năng động, sáng tạo, dám nghĩ, dám làm. Mỗi quân nhân \"cần thích ứng nhanh với thực tiễn, vươn lên làm chủ khoa học - công nghệ và vũ khí trang bị kỹ thuật hiện đại, hoàn thành xuất sắc nhiệm vụ được giao\".', '0'], ['Cạnh đó, thanh niên quân đội và thanh niên tiền phon cũng phải thực hiện tốt công tác dân vận, tham gia tích cực vào các chương trình an sinh xã hội, xây dựng nông thôn mới, phòng, chống khắc phục thiên tai, dịch bệnh, xóa đói giảm nghèo.', 'Ở đó, nữ nhà báo chi trả khoảng 3 USD cho một món ăn và có những trải nghiệm hài lòng về chất lượng ẩm thực Việt Nam.', '0'], ['Gương mặt trẻ tiêu biểu, Gương mặt trẻ triển vọng toàn quân là danh hiệu được Bộ Quốc phòng và Giáo dục tổ chức bình chọn và tuyên dương hàng năm hai lần', 'Gương mặt trẻ tiêu biểu, Gương mặt trẻ triển vọng toàn quân là danh hiệu được Bộ Quốc phòng tổ chức bình chọn và tuyên dương hàng năm. Ba năm qua, có 30 quân nhân được tuyên dương Gương mặt trẻ tiêu biểu toàn quân. 100% số này hoàn thành tốt và xuất sắc nhiệm vụ, được các cấp khen thưởng, 12 người được bổ nhiệm cương vị công tác cao.', '1'], ['Gương mặt trẻ tiêu biểu, Gương mặt trẻ triển vọng toàn quân là danh hiệu được Bộ Quốc phòng và Giáo dục tổ chức bình chọn và tuyên dương hàng năm hai lần', 'Chủ tịch nước Võ Văn Thưởng đánh giá cao những quân nhân xuất sắc được vinh danh. 10 gương mặt trẻ tiêu biểu, 43 gương mặt triển vọng toàn quân năm nay \"đều có thành tích nổi bật, xuất sắc trên các lĩnh vực, đã trải qua khổ luyện và phấn đấu bền bỉ, không ngừng\". Vì vậy, ông giao chỉ huy và cơ quan chính trị toàn quân \"hết sức chăm lo\", tạo điều kiện cho thanh niên quân đội học tập, rèn luyện, cống hiến, tiến bộ và trưởng thành.', '0'], ['Gương mặt trẻ tiêu biểu, Gương mặt trẻ triển vọng toàn quân là danh hiệu được Bộ Quốc phòng và Giáo dục tổ chức bình chọn và tuyên dương hàng năm hai lần', 'Danh sách 10 gương mặt trẻ tiêu biểu toàn quân năm 2022:', '0'], ['Gương mặt trẻ tiêu biểu, Gương mặt trẻ triển vọng toàn quân là danh hiệu được Bộ Quốc phòng và Giáo dục tổ chức bình chọn và tuyên dương hàng năm hai lần', 'Theo Phó chủ tịch UBND TP Cần Thơ, để đẩy nhanh việc giải phóng mặt bằng, địa phương có thể tổ chức bốc thăm giao nền tái định cư cho người dân trước khi có quyết định áp giá nền; tính đến phương án tái định cư phân tán (hỗ trợ tiền cho người dân tự mua nền)', '0'], ['10 gương mặt trẻ tiêu biểu, 43 gương mặt triển vọng toàn quân, 50 gương mặt nhân ái năm nay \"đều có thành tích nổi bật, xuất sắc trên các lĩnh vực, đã trải qua khổ luyện và phấn đấu bền bỉ, không ngừng\".', 'Chủ tịch nước Võ Văn Thưởng đánh giá cao những quân nhân xuất sắc được vinh danh. 10 gương mặt trẻ tiêu biểu, 43 gương mặt triển vọng toàn quân năm nay \"đều có thành tích nổi bật, xuất sắc trên các lĩnh vực, đã trải qua khổ luyện và phấn đấu bền bỉ, không ngừng\". Vì vậy, ông giao chỉ huy và cơ quan chính trị toàn quân \"hết sức chăm lo\", tạo điều kiện cho thanh niên quân đội học tập, rèn luyện, cống hiến, tiến bộ và trưởng thành.', '1'], ['10 gương mặt trẻ tiêu biểu, 43 gương mặt triển vọng toàn quân, 50 gương mặt nhân ái năm nay \"đều có thành tích nổi bật, xuất sắc trên các lĩnh vực, đã trải qua khổ luyện và phấn đấu bền bỉ, không ngừng\".', 'Gương mặt trẻ tiêu biểu, Gương mặt trẻ triển vọng toàn quân là danh hiệu được Bộ Quốc phòng tổ chức bình chọn và tuyên dương hàng năm. Ba năm qua, có 30 quân nhân được tuyên dương Gương mặt trẻ tiêu biểu toàn quân. 100% số này hoàn thành tốt và xuất sắc nhiệm vụ, được các cấp khen thưởng, 12 người được bổ nhiệm cương vị công tác cao.', '0']]\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "dataset = []\n",
        "LOAD_DIR = \"/content/drive/MyDrive/UIT fake news/rerank_dataset.csv\"\n",
        "with open(LOAD_DIR, 'r', encoding='utf-8-sig') as file:\n",
        "    csvreader = csv.reader(x.replace('\\0', '') for x in file)\n",
        "    header = next(csvreader)\n",
        "    for row in csvreader:\n",
        "        dataset.append(row)\n",
        "print(header)\n",
        "print(dataset[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUyVe2Bdk0fF",
        "outputId": "d6fb6860-0780-4c66-9378-3a637deaa9cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "before: 103639 rows\n",
            "after: 25956 rows\n"
          ]
        }
      ],
      "source": [
        "print(f\"before: {len(dataset)} rows\")\n",
        "dataset =  [i for i in dataset if i[2] == '1']\n",
        "#  = list(filter(lambda x: x[2] == 0, dataset))\n",
        "print(f\"after: {len(dataset)} rows\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcF0v5ZWWVBz",
        "outputId": "8b187444-4dfe-4602-b849-76a1dd3504dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20764\n",
            "5192\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "SPLIT = int(len(dataset)*0.8)\n",
        "\n",
        "random.shuffle(dataset)\n",
        "train_set = dataset[:SPLIT]\n",
        "test_set = dataset[SPLIT:]\n",
        "\n",
        "print(len(train_set))\n",
        "print(len(test_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSDBkarji6qg"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import InputExample\n",
        "from tqdm.auto import tqdm  # so we see progress bar\n",
        "\n",
        "train_samples = []\n",
        "for row in tqdm(train_set):\n",
        "    train_samples.append(InputExample(\n",
        "        texts=[row[0], row[1]]\n",
        "    ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xykKiAZQciZ1"
      },
      "outputs": [],
      "source": [
        "queries = [x[0] for x in test_set]\n",
        "corpus = [x[1] for x in test_set]\n",
        "print(len(queries))\n",
        "print(len(corpus))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWpduyOCcr7L"
      },
      "outputs": [],
      "source": [
        "print(queries[1])\n",
        "print(corpus[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lebKecapbo1f"
      },
      "outputs": [],
      "source": [
        "#  queries: Dict[str, str],  #qid => query\n",
        "#  corpus: Dict[str, str],  #cid => doc\n",
        "#  relevant_docs: Dict[str, Set[str]],  #qid => Set[cid]\n",
        "\n",
        "txt2id_query = {x:i for i,x in enumerate(queries)}\n",
        "id2txt_query = {i:x for i,x in enumerate(queries)}\n",
        "\n",
        "txt2id_corpus = {x:i for i,x in enumerate(corpus)}\n",
        "id2txt_corpus = {i:x for i,x in enumerate(corpus)}\n",
        "\n",
        "relevant_docs = {x:set([x]) for x in range(0, len(corpus))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_kQTZ1XeicT"
      },
      "outputs": [],
      "source": [
        "print(id2txt_query)\n",
        "print(id2txt_corpus)\n",
        "print(relevant_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ap9NtpQ25iu9"
      },
      "source": [
        "# Trainning model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_4zDkxnoN45"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uu5lxfudk311"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import datasets\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "loader = datasets.NoDuplicatesDataLoader(\n",
        "    train_samples, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0EsXSAzxk-aN",
        "outputId": "fa6ddb77-d9bd-4e89-cae9-8afb2c43c9ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SentenceTransformer(\n",
              "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: RobertaModel \n",
              "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
              ")"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sentence_transformers import models, SentenceTransformer\n",
        "\n",
        "bert = models.Transformer('keepitreal/vietnamese-sbert')\n",
        "# bert = models.Transformer('vinai/phobert-large')\n",
        "pooler = models.Pooling(\n",
        "    bert.get_word_embedding_dimension(),\n",
        "    pooling_mode_mean_tokens=True\n",
        ")\n",
        "\n",
        "model = SentenceTransformer(modules=[bert, pooler])\n",
        "\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-vzMy3EXlCAn"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import losses\n",
        "from sentence_transformers import evaluation\n",
        "loss = losses.MultipleNegativesRankingLoss(model)\n",
        "evaluator = evaluation.InformationRetrievalEvaluator(id2txt_query, id2txt_corpus, relevant_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hH2PNzKFlC1A"
      },
      "outputs": [],
      "source": [
        "epochs = 10\n",
        "warmup_steps = int(len(loader) * epochs * 0.1)\n",
        "model.fit(\n",
        "    train_objectives=[(loader, loss)],\n",
        "    epochs=epochs,\n",
        "    warmup_steps=warmup_steps,\n",
        "    save_best_model= True,\n",
        "    output_path='./sbert_test_mnr_withevaluator',\n",
        "    show_progress_bar=True,\n",
        "    evaluator=evaluator,\n",
        "    evaluation_steps= 10,\n",
        "    callback = callbackfn\n",
        ")  # I set 'show_progress_bar=False' as it printed every step\n",
        "#    on to a new line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVXRgQNRjpYn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"/content/sbert_test_mnr_withevaluator/eval/Information-Retrieval_evaluation_results.csv\")\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfSvwe4t5JqG"
      },
      "source": [
        "# Pushing models to hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyY9oscl4y9A"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, AutoTokenizer, AutoModel\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('./sbert_test_mnr_withevaluator')\n",
        "model = AutoModel.from_pretrained('./sbert_test_mnr_withevaluator')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUMG8WMU41W3"
      },
      "outputs": [],
      "source": [
        "!pip install huggingface_hub\n",
        "!huggingface-cli login --token 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"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxPJs5jF9IuU"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import create_repo\n",
        "# create_repo(\"Oztobuzz/phoBert_test\", private=False)\n",
        "model.push_to_hub(\"Oztobuzz/sbert_mnr_10_epoch_v1\")\n",
        "tokenizer.push_to_hub(\"Oztobuzz/sbert_mnr_10_epoch_v1\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
