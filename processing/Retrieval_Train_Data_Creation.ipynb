{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_link = \"/content/drive/MyDrive/UIT_Fact_Checking_Contest/Data/Processed_public_data/public_processed_train.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "def get_embedding(corpus):\n",
    "  tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
    "\n",
    "  bm25 = BM25Okapi(tokenized_corpus)\n",
    "  return bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "list_sent1 = []\n",
    "list_sent2 = []\n",
    "list_label = []\n",
    "\n",
    "for key in tqdm(data.keys()):\n",
    "  dt = data[key]\n",
    "  while True:\n",
    "    key_not_info = random.choice(list(data.keys()))\n",
    "    if key_not_info != key: break\n",
    "  context = dt['context'].split('\\n\\n')\n",
    "  evidence = dt['evidence']\n",
    "  claim = dt['claim']\n",
    "  tokenized_query = evidence.split(\" \")\n",
    "\n",
    "  all_embedding = get_embedding(context)\n",
    "  # texts = corpus_embedding.get_top_n(tokenized_query, corpus, n=30)\n",
    "  score = all_embedding.get_scores(tokenized_query)\n",
    "\n",
    "  top_3_max_indices = sorted(range(len(score)), key=lambda i: score[i], reverse=True)[:3]\n",
    "\n",
    "  flag = False\n",
    "  for idx in top_3_max_indices:\n",
    "    list_sent1.append(claim)\n",
    "    list_sent2.append(context[idx])\n",
    "\n",
    "    if flag == False:\n",
    "      list_label.append(1)\n",
    "      flag = True\n",
    "    else:\n",
    "      list_label.append(0)\n",
    "\n",
    "  #nei_info\n",
    "  evidence_nei = data[key_not_info]['evidence']\n",
    "  list_sent1.append(claim)\n",
    "  list_sent2.append(evidence_nei)\n",
    "  list_label.append(0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"sent1\" : list_sent1,\n",
    "    \"sent2\" : list_sent2,\n",
    "    \"label\" : list_label\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/content/drive/MyDrive/UIT_Fact_Checking_Contest/Data/Processed_public_data/rerank_dataset.csv\",index=False,escapechar='\\\\')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
