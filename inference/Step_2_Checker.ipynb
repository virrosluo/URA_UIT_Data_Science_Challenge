{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import phonlp\n",
    "from underthesea import dependency_parse\n",
    "from typing import List, Dict, Tuple\n",
    "from itertools import chain\n",
    "from vncorenlp import VnCoreNLP\n",
    "from tqdm import tqdm\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH_UNIT = ['mm', 'cm', 'dm', 'm', 'km']\n",
    "APPROXIMATION = ['khoảng', 'xấp xỉ', 'gần', 'cỡ',]\n",
    "NEGATION_WORD = [\"không\", \"chưa\", \"chẳng\", \"chả\", \"khỏi\", \"đâu\", \"chả\", \"chớ\"]\n",
    "VNCORENLP_PATH = \"/kaggle/working/vncorenlp/VnCoreNLP-1.2.jar\"\n",
    "PHONLP_PATH = '/kaggle/working/phonlp'\n",
    "ACRONYM_PATH = '/kaggle/input/acronym-dict/acronym.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLAIM_FILE = \"..result/private_test_claim_annotation.txt\"\n",
    "RETRIEVAL_FILE = '../result/retrieval_result/private_test_retrieval_v1_top5_top_5.json'\n",
    "EVIDENCE_FILE = '../result/private_test_retrieval_v1_top5_top_5_annotation.txt'\n",
    "OUT_FILE = '../result/private_test_retrieval_v1_top5_top_5_checked.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vncorenlp_model = VnCoreNLP(VNCORENLP_PATH, max_heap_size='-Xmx16g')\n",
    "phonlp_model = phonlp.load(save_dir=PHONLP_PATH).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Annotator:\n",
    "    def __init__(self, vncorenlp_path, phonlp_path):\n",
    "        self.vncorenlp_model = VnCoreNLP(vncorenlp_path, max_heap_size='-Xmx16g')\n",
    "        self.phonlp_model= phonlp.load(save_dir=phonlp_path)\n",
    "    \n",
    "    def annotate(self, text: str):\n",
    "        \"\"\"\n",
    "        A function performs word segmentation and annotation.\n",
    "        As phonlp and vncorenlp return batch output, we need\n",
    "        to flatten it.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text: str\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        annotation: List[List, List, List, List[List]]\n",
    "            The lists are in the following order:\n",
    "                - Segmented words\n",
    "                - POS Tag\n",
    "                - Named Entity Tag\n",
    "                - Dependency Tag\n",
    "        \"\"\"\n",
    "        segmented_input = \" \".join([\" \".join(x) for x in self.vncorenlp_model.tokenize(text)])\n",
    "        batch_annotation = self.phonlp_model.annotate(text=segmented_input)\n",
    "        \n",
    "        annotation = np.squeeze(batch_annotation).tolist()\n",
    "        annotation[1] = list(chain.from_iterable(annotation[1]))\n",
    "\n",
    "        # phonlp_model.print_out(batch_annotation)\n",
    "\n",
    "        return annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Formatter:\n",
    "    def __init__(self, LENGTH_UNIT):\n",
    "        self.LENGTH_UNIT = LENGTH_UNIT\n",
    "    \n",
    "    def __preprocess_text(self, text: str) -> str:    \n",
    "        text = re.sub(r\"['\\\"\\.\\?:\\-!]\", \" \", text)\n",
    "        text = re.sub(r\"\\n\", \"\", text)\n",
    "        text = text.strip()\n",
    "        text = text[1:].strip() if text[0]=='.' else text\n",
    "        text = text[:-1].strip() if text[-1]=='.' else text\n",
    "        text = \" \".join(text.split())\n",
    "        # text = text.lower()\n",
    "        return text \n",
    "    \n",
    "    \n",
    "    def __clean(self, text: str) -> str:\n",
    "        def split_number_with_unit(text: str) -> str:\n",
    "            # Format 1m -> 1 m; 2dm -> 2 dm\n",
    "            checkUnitPattern = [re.search(f\"^[0-9]+{unit}$\", text) is not None for unit in self.LENGTH_UNIT]\n",
    "            isContainUnitPattern =  any(checkUnitPattern)\n",
    "\n",
    "            if not isContainUnitPattern:\n",
    "                return text\n",
    "\n",
    "            unit_index = checkUnitPattern.index(True)\n",
    "\n",
    "            return re.sub(f\"{self.LENGTH_UNIT[unit_index]}\", f\" {self.LENGTH_UNIT[unit_index]}\", text)\n",
    "        \n",
    "        # Split number with unit\n",
    "        text = \" \".join([split_number_with_unit(word) for word in text.split()])\n",
    "        return text\n",
    "    \n",
    "    def __normalize(self, text: str) -> str: \n",
    "        # Convertword to number, except year casepreprocess_text\n",
    "        # TODO\n",
    "        return text\n",
    "    \n",
    "    def format_text(self, text: str) -> str:\n",
    "        text = self.__preprocess_text(text)\n",
    "        text = self.__clean(text)\n",
    "        text = self.__normalize(text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Checker:\n",
    "    def __init__(self, annotator, formatter, acronym_path):\n",
    "        self.formatter = formatter\n",
    "        self.annotator = annotator\n",
    "        self.acronym_dict = json.load(open(acronym_path))\n",
    "    \n",
    "    def __similar(self, a, b):\n",
    "        return SequenceMatcher(None, a, b).ratio()\n",
    "        \n",
    "    def __check_same_length(self, annotation_1, annotation_2):        \n",
    "        def get_different_index_from_two_list(list_1, list_2):\n",
    "            if len(list_1) != len(list_2):\n",
    "                raise Exception(\"Only accept 2 lists with the same length\")\n",
    "            return [x for x in range(len(list_1)) if list_1[x]!=list_2[x]]\n",
    "        \n",
    "        def isArcronym(word_1, word_2):\n",
    "            if word_1 in self.acronym_dict.keys():\n",
    "                if word_2 in self.acronym_dict[word_1]: \n",
    "                    return True\n",
    "            else:\n",
    "                return False\n",
    "        \n",
    "        different_index = get_different_index_from_two_list(\n",
    "            annotation_1[0],\n",
    "            annotation_2[0],\n",
    "        )\n",
    "\n",
    "        check_list = list()\n",
    "        for index in different_index:\n",
    "            if (\n",
    "                annotation_1[1][index] == annotation_2[1][index] == 'Np' and \n",
    "                annotation_1[0][index] not in annotation_2[0] and \n",
    "                annotation_2[0][index] not in annotation_1[0]\n",
    "            ):\n",
    "                print(\"PROPER NOUND\")\n",
    "                check_list.append('not_equal')\n",
    "            elif (annotation_1[1][index] == annotation_2[1][index] == 'M' and \n",
    "                annotation_1[0][index] not in annotation_2[0] and \n",
    "                annotation_2[0][index] not in annotation_1[0]\n",
    "            ):\n",
    "                print(\"NUMBER\")\n",
    "                check_list.append('not_equal')\n",
    "            elif annotation_1[1][index] == annotation_2[1][index] == 'Nu':\n",
    "                print(\"UNIT\")\n",
    "                check_list.append('not_equal')\n",
    "            elif isArcronym(annotation_1[0][index], annotation_2[0][index]):\n",
    "                print(\"ACRONYM\")\n",
    "                check_list.append('not_equal')\n",
    "\n",
    "        return 'not_equal' if 'not_equal' in check_list else 'unknown'\n",
    "    \n",
    "    def __check_negation(self, annotation_1, annotation_2):\n",
    "        def list_subtraction(list_1, list_2):\n",
    "            ret_list = list_2.copy()\n",
    "            for word in list_1:\n",
    "                if word in ret_list:\n",
    "                    ret_list.remove(word)\n",
    "            return ret_list\n",
    "        \n",
    "        def check_contain_negation(list_1, list_2):\n",
    "            list_1_minus_2 = list_subtraction(list_1, list_2)\n",
    "            list_2_minus_1 = list_subtraction(list_2, list_1)\n",
    "            \n",
    "            print(list_1_minus_2)\n",
    "            print(list_2_minus_1)\n",
    "            \n",
    "            is_list_1_contain_negation_word =  all([x in NEGATION_WORD for x in list_1_minus_2]) and len(list_1_minus_2) != 0\n",
    "            is_list_2_contain_negation_word =  all([x in NEGATION_WORD for x in list_2_minus_1]) and len(list_2_minus_1) != 0\n",
    "            \n",
    "            if (is_list_1_contain_negation_word ^ is_list_2_contain_negation_word):\n",
    "                return True\n",
    "\n",
    "            return False\n",
    "    \n",
    "        if check_contain_negation(annotation_1[0],annotation_2[0]):\n",
    "            print(\"NEGATION\")\n",
    "            return 'not_equal'\n",
    "        \n",
    "        return 'unkown'\n",
    "    \n",
    "    def __check_interval(self):\n",
    "        # TODO\n",
    "        return 'unknown'\n",
    "            \n",
    "    def check(self, text_1=None, text_2=None, annotation_1=None, annotation_2=None):\n",
    "        # try:\n",
    "        # Format inputs\n",
    "        if annotation_1==None and annotation_2==None:\n",
    "            text_1 = self.formatter.format_text(text_1)\n",
    "            text_2 = self.formatter.format_text(text_2)\n",
    "\n",
    "            # Create Text Annotation\n",
    "            annotation_1 = self.annotator.annotate(text_1)\n",
    "            annotation_2 = self.annotator.annotate(text_2)\n",
    "        else:\n",
    "            text_1 = \" \".join(annotation_1[0])\n",
    "            text_2 = \" \".join(annotation_2[0])\n",
    "\n",
    "        # Case 1: Return if 2 sentences are exactly the same\n",
    "        if text_1 == text_2:\n",
    "            print(\"EXACT MATCH\")\n",
    "            return \"equal\"\n",
    "\n",
    "        ret_list = list()\n",
    "        # Case 2: Same length\n",
    "        if (\n",
    "            (type(annotation_1[0])==list and type(annotation_2[0])==list) and\n",
    "            len(annotation_1[0]) == len(annotation_2[0]) and # Check same length\n",
    "            self.__similar(text_1, text_2) >=0.5 and\n",
    "            self.__check_same_length(annotation_1, annotation_2) == 'not_equal' # Check smaller cases\n",
    "        ):\n",
    "            return 'not_equal'\n",
    "\n",
    "        # Case 3: Negation\n",
    "        if annotation_1[0][0] == annotation_2[0][0] and self.__check_negation(annotation_1, annotation_2) == 'not_equal':\n",
    "            return 'not_equal'\n",
    "\n",
    "        if self.__check_interval() == 'not_equal':\n",
    "            return 'not_equal'\n",
    "\n",
    "        return \"unkown\"\n",
    "        # except Exception as error:\n",
    "            # print(error)\n",
    "            # return \"unkown\"        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatter = Formatter(LENGTH_UNIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open(RETRIEVAL_FILE))\n",
    "# Get Evidence\n",
    "claim = [data[key]['claim'] for key in data.keys()]\n",
    "if type(claim[0]) == list:\n",
    "    claim = list(itertools.chain(*claim))\n",
    "# Word Segmentation\n",
    "print(\"Word Segmentating\")\n",
    "claim = [formatter.format_text(x) for x in claim]\n",
    "claim = [\" \".join([\" \".join(x) for x in vncorenlp_model.tokenize(text)]) for text in claim]\n",
    "# Create Text Files\n",
    "with open('temp.txt', 'w') as f:\n",
    "    f.write('\\n'.join(claim))\n",
    "# Annotation\n",
    "print(\"Annotating\")\n",
    "phonlp_model.annotate(input_file='temp.txt', output_file=CLAIM_FILE, batch_size=8)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_inference(file_name):\n",
    "    # Create output filename\n",
    "    output_file = file_name.split('/')[-1].split('.')[0] + \"_annotation.txt\"\n",
    "    # Read Json File\n",
    "    data = json.load(open(file_name))\n",
    "    # Get Evidence\n",
    "    evidence = [data[key]['evidence'] for key in data.keys()]\n",
    "    if type(evidence[0]) == list:\n",
    "        print(len(list(itertools.chain(*evidence))))\n",
    "        evidence = list(itertools.chain(*evidence))\n",
    "    # Word Segmentation\n",
    "    print(\"Word Segmentating\")\n",
    "    evidence = [formatter.format_text(x) for x in evidence]\n",
    "    evidence = [\" \".join([\" \".join(x) for x in vncorenlp_model.tokenize(text)]) for text in evidence]\n",
    "    print(len(evidence))\n",
    "    # Create Text Files\n",
    "    with open('temp.txt', 'w') as f:\n",
    "        f.write('\\n'.join(evidence))\n",
    "    # Annotation\n",
    "    print(\"Annotating\")\n",
    "    phonlp_model.annotate(input_file='temp.txt', output_file=output_file, batch_size=8)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_inference(RETRIEVAL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_annotation_format(annotation_list):\n",
    "    index = [x[0] for x in annotation_list]\n",
    "    word = [x[1] for x in annotation_list]\n",
    "    pos = [x[2] for x in annotation_list] \n",
    "    ner = [x[3] for x in annotation_list]\n",
    "    dp_index = [x[4] for x in annotation_list]\n",
    "    dp_tag = [x[5] for x in annotation_list]\n",
    "    dp = [[dp_index[x], dp_tag[x]] for x in range(len(dp_index))]\n",
    "    \n",
    "    return [word, pos, ner, dp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotation_single_evidence(file_name):\n",
    "    f = open(file_name)\n",
    "    annotation = list()\n",
    "    temp = list()\n",
    "    for line in f:\n",
    "        if line != \"\\n\":\n",
    "            text = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            if text[0] == '1' and temp!=list():\n",
    "                annotation.append(temp)\n",
    "                temp = list()\n",
    "            temp.append(text)\n",
    "            \n",
    "    annotation.append(temp)\n",
    "    annotation = [create_annotation_format(x) for x in annotation]\n",
    "    return annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotation_multiple_evidence(file_name, original_evidence):\n",
    "    f = open(file_name).readlines()\n",
    "    annotation = list()\n",
    "    temp = list()\n",
    "    for line in f:\n",
    "        if line != \"\\n\":\n",
    "            text = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            if text[0] == '1' and temp!=list():\n",
    "                annotation.append(temp)\n",
    "                temp = list()   \n",
    "            temp.append(text)\n",
    "            \n",
    "    annotation.append(temp)\n",
    "    start = 0\n",
    "    new_annotation = list()\n",
    "    for i in range(len(original_evidence)):\n",
    "        length = len(original_evidence[i])\n",
    "        end = start + length\n",
    "        if i!= len(original_evidence)-1:\n",
    "            new_annotation.append([create_annotation_format(x) for x in annotation[start:end]])\n",
    "        else:\n",
    "            new_annotation.append([create_annotation_format(x) for x in annotation[start:]])\n",
    "        start = end\n",
    "   \n",
    "    return new_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open(RETRIEVAL_FILE))\n",
    "evidence = [data[key]['evidence'] for key in data.keys()]\n",
    "claim_annotation = load_annotation_single_evidence(CLAIM_FILE)\n",
    "evidence_annotation = load_annotation_multiple_evidence(EVIDENCE_FILE, evidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checker = Checker(None, None, ACRONYM_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_result = [\n",
    "    [checker.check(annotation_1=claim_annotation[sample_index], annotation_2=evidence_annotation[sample_index][evidence_index]) for evidence_index in range(len(evidence_annotation[sample_index]))] \n",
    "    for sample_index in range(len(claim_annotation))\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_verdict(text):\n",
    "    return \"REFUTED\" if text == 'not_equal' else \"SUPPORTED\" if text == 'equal' else ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, key in enumerate(list(data.keys())):\n",
    "    data[key]['verdict'] = [return_verdict(x) for x in check_result[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(OUT_FILE, \"w\") as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
